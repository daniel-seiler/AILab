{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78743464-286f-48d1-ac28-63a528790472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import  Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import kagglehub\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "import torchvision.utils\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torchvision.models as mdl\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "writer = SummaryWriter('runs/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "\n",
    "\n",
    "path_set_1 = kagglehub.dataset_download('vipoooool/new-plant-diseases-dataset')\n",
    "path_set_2 = kagglehub.dataset_download('amandam1/healthy-vs-diseased-leaf-image-dataset')\n",
    "\n",
    "path_set_1 = os.path.join(path_set_1, 'New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)')\n",
    "\n",
    "print (f\"Path set 1: '{path_set_1}'\")\n",
    "print (f\"Path set 2: {path_set_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b144b57",
   "metadata": {},
   "source": [
    "## Dataset Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c24ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsdata params\n",
    "random_erase=0.1\n",
    "scale_factor = 28\n",
    "batch_size = 64\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "\n",
    "# Leave this on False ... 70.000 images will crash the RAM\n",
    "move_to_cuda_preprocess = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((width, height)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomCrop(224, padding=4),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir=\".\", transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels_df.iloc[idx, 2] if 'Labels' in self.labels_df.columns else -1\n",
    "        label = np.float32(label if label == 0 or label == 1 else 0)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c85969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(root_dir, csv_path):\n",
    "    data = []\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    index = 0\n",
    "    num_label_0 = 0\n",
    "    num_label_1 = 0\n",
    "\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.JPG', '.JPEG')):\n",
    "                subfolder_name = os.path.basename(subdir)\n",
    "                label = 0 if subfolder_name.endswith('healthy') else 1\n",
    "                if label == 0:\n",
    "                    num_label_0 += 1\n",
    "                else:\n",
    "                    num_label_1 += 1\n",
    "\n",
    "                # Relative path from root (./train or ./valid)\n",
    "                rel_path = os.path.relpath(os.path.join(subdir, file), '.')\n",
    "\n",
    "                data.append([index, rel_path.replace(\"\\\\\", \"/\"), label])\n",
    "                index += 1\n",
    "    print(f\"Number of healthy images: {num_label_0}\")\n",
    "    print(f\"Number of diseased images: {num_label_1}\")\n",
    "    df = pd.DataFrame(data, columns=['Index', 'Image', 'Labels'])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {len(df)} entries to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0423d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv(csv_path, train_csv_path, valid_csv_path, split_ratio=0.8, overwrite=False):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    train_df = df.sample(frac=split_ratio, random_state=seed)\n",
    "    valid_df = df.drop(train_df.index)\n",
    "\n",
    "    # If train_csv_path exists, append and update index\n",
    "    if os.path.exists(train_csv_path) and not overwrite:\n",
    "        existing_train = pd.read_csv(train_csv_path)\n",
    "        train_df = pd.concat([existing_train, train_df], ignore_index=True)\n",
    "        train_df['Index'] = range(len(train_df))\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(train_csv_path), exist_ok=True)\n",
    "        train_df['Index'] = range(len(train_df))\n",
    "\n",
    "    # If valid_csv_path exists, append and update index\n",
    "    if os.path.exists(valid_csv_path) and not overwrite:\n",
    "        existing_valid = pd.read_csv(valid_csv_path)\n",
    "        valid_df = pd.concat([existing_valid, valid_df], ignore_index=True)\n",
    "        valid_df['Index'] = range(len(valid_df))\n",
    "    else:\n",
    "        valid_df['Index'] = range(len(valid_df))\n",
    "        os.makedirs(os.path.dirname(valid_csv_path), exist_ok=True)\n",
    "\n",
    "    train_df.to_csv(train_csv_path, index=False)\n",
    "    valid_df.to_csv(valid_csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved {len(train_df)} training entries to {train_csv_path}\")\n",
    "    print(f\"Saved {len(valid_df)} validation entries to {valid_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddda436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(csv_path_1, csv_path_2, model):\n",
    "    \n",
    "    model.eval()\n",
    "    dataset1 = CustomDataset(csv_file=csv_path_1, transform=transform)\n",
    "    dataset2 = CustomDataset(csv_file=csv_path_2, transform=transform)\n",
    "\n",
    "    loader1 = torch.utils.data.DataLoader(dataset1, batch_size=64, shuffle=False)\n",
    "    loader2 = torch.utils.data.DataLoader(dataset2, batch_size=64, shuffle=False)\n",
    "\n",
    "    def extract_embeddings(loader):\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for images, _ in tqdm(loader, desc=\"Extracting embeddings\"):\n",
    "                images = images.to(device)\n",
    "                feats = model(images)\n",
    "                embeddings.append(feats.cpu())\n",
    "        return torch.cat(embeddings, dim=0)\n",
    "\n",
    "    embeddings1 = extract_embeddings(loader1)\n",
    "    embeddings2 = extract_embeddings(loader2)\n",
    "    min_len = min(len(embeddings1), len(embeddings2))\n",
    "    embeddings1 = embeddings1[:min_len]\n",
    "    embeddings2 = embeddings2[:min_len]\n",
    "\n",
    "    def calculate_fid(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "        # Calculate the mean and covariance difference\n",
    "        diff = mu1 - mu2\n",
    "        covmean, _ = sqrtm(sigma1 @ sigma2, disp=False)\n",
    "\n",
    "        # Numerical stability\n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "\n",
    "        fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "        return fid\n",
    "\n",
    "    # Convert to numpy\n",
    "    embeddings1_np = embeddings1.numpy()\n",
    "    embeddings2_np = embeddings2.numpy()\n",
    "\n",
    "    # Compute mean and covariance\n",
    "    mu1 = np.mean(embeddings1_np, axis=0)\n",
    "    mu2 = np.mean(embeddings2_np, axis=0)\n",
    "    sigma1 = np.cov(embeddings1_np, rowvar=False)\n",
    "    sigma2 = np.cov(embeddings2_np, rowvar=False)\n",
    "\n",
    "    # Calculate FID\n",
    "    fid_score = calculate_fid(mu1, sigma1, mu2, sigma2)\n",
    "    print(\"FID Score:\", fid_score)\n",
    "\n",
    "    all_embeddings = torch.cat([embeddings1, embeddings2], dim=0).numpy()\n",
    "    labels = np.array([0]*len(embeddings1) + [1]*len(embeddings2))\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(embeddings_2d[labels==0,0], embeddings_2d[labels==0,1], alpha=0.5, label='Dataset 1')\n",
    "    plt.scatter(embeddings_2d[labels==1,0], embeddings_2d[labels==1,1], alpha=0.5, label='Dataset 2')\n",
    "    plt.legend()\n",
    "    plt.title(\"t-SNE of Dataset Embeddings\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run for both train and valid\n",
    "generate_csv(os.path.join(path_set_1, './train'), 'data/train.csv')\n",
    "generate_csv(os.path.join(path_set_1, './valid'), 'data/valid.csv')\n",
    "generate_csv(path_set_2, 'data/dataset_2.csv')\n",
    "os.makedirs('./data/evaluate', exist_ok=True)\n",
    "shutil.copy('data/valid.csv', 'data/evaluate/valid.csv')\n",
    "split_csv('data/dataset_2.csv', 'data/train_2.csv', 'data/test.csv')\n",
    "split_csv('data/train_2.csv', 'data/train.csv', 'data/valid.csv')\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "min_count = df['Labels'].value_counts().min()\n",
    "\n",
    "# Sample min_count from each class\n",
    "df_minority = df[df['Labels'] == df['Labels'].value_counts().idxmin()]\n",
    "df_majority = df[df['Labels'] == df['Labels'].value_counts().idxmax()].sample(min_count, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "df_balanced = pd.concat([df_minority, df_majority]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_balanced.to_csv('data/train_undersampled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75053724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_and_save_image(idx, row, transform, output_dir):\n",
    "    img_path = os.path.join('.', row['Image'])\n",
    "    try:\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        processed_image = transform(image)  # Tensor C,H,W\n",
    "        label = row['Labels'] if not pd.isna(row['Labels']) else -1\n",
    "        label = np.float32(label if label == 0 or label == 1 else 0)\n",
    "\n",
    "        # Convert tensor back to PIL Image for saving\n",
    "        to_pil = transforms.ToPILImage()\n",
    "        pil_img = to_pil(processed_image)\n",
    "\n",
    "        # Save processed image with zero-padded index filename\n",
    "        out_name = f\"{idx:06d}.png\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "        pil_img.save(out_path)\n",
    "\n",
    "        return pil_img, label\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "def preprocess_and_save_images(csv_file, output_dir, output_csv, transform, num_workers=8):\n",
    "    if os.path.exists(output_csv):\n",
    "        print(f\"Output CSV '{output_csv}' already exists. Skipping preprocessing.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    processed_entries = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_and_save_image, idx, row, transform, output_dir)\n",
    "            for idx, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        # Wrap the futures list with tqdm, then call result() inside the loop\n",
    "        for f in tqdm(futures, desc=\"Preprocessing & saving images\"):\n",
    "            out_name, label = f.result()\n",
    "            if out_name is not None:\n",
    "                processed_entries.append([out_name, label])\n",
    "\n",
    "    processed_df = pd.DataFrame(processed_entries, columns=['Image', 'Labels'])\n",
    "    processed_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved processed images to {output_dir} and CSV to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomProcessedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.labels_df.iloc[idx]['Image']\n",
    "        # If saved as PNG, just load and convert to tensor\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transforms.ToTensor()(image)  # Only if needed, otherwise remove\n",
    "        label = np.float32(self.labels_df.iloc[idx]['Labels'])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42745c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = torch.nn.Identity()\n",
    "# model = model.to(device)\n",
    "# evaluate_dataset('data/evaluate/valid.csv', 'data/dataset_2.csv', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset and data loaders\n",
    "preprocess_and_save_images('data/train_undersampled.csv', 'data/processed_images/train', 'data/processed_train.csv', transform, num_workers=16)\n",
    "preprocess_and_save_images('data/valid.csv', 'data/processed_images/valid', 'data/processed_valid.csv', transform, num_workers=16)\n",
    "\n",
    "train_dataset = CustomProcessedDataset(csv_file='data/processed_train.csv')\n",
    "val_dataset = CustomProcessedDataset(csv_file='data/processed_valid.csv')\n",
    "test_dataset = CustomDataset(csv_file='data/test.csv', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba245022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_dataloader(sampler, dataset,batch_size=1, shuffle=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img, label in tqdm(dataset):\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    data = torch.stack(data)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(data, labels),\n",
    "    batch_size=batch_size, shuffle=shuffle, sampler=sampler)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampler(dataset, weighted=False):\n",
    "    if weighted:\n",
    "        # WeightedRandomSampler against class imbalance\n",
    "        labels = dataset.labels_df['Labels'].values\n",
    "        class_sample_count = np.array([len(np.where(labels == t)[0]) for t in np.unique(labels)])\n",
    "        weights = 1. / class_sample_count\n",
    "        samples_weights = np.array([weights[int(t)] for t in labels])\n",
    "        samples_weights = torch.from_numpy(samples_weights).float()\n",
    "\n",
    "        return torch.utils.data.WeightedRandomSampler(samples_weights, len(samples_weights), replacement=True)\n",
    "    else:\n",
    "        return torch.utils.data.RandomSampler(dataset, replacement=True, num_samples=len(dataset))\n",
    " \n",
    "\n",
    "# Data loaders\n",
    "train_sampler = get_sampler(train_dataset)\n",
    "validation_sampler = get_sampler(val_dataset)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=16)\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, sampler=validation_sampler, num_workers=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1717d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66cb2735",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_dataset)\n",
    "next(dataiter)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(labels)\n",
    "\n",
    "print(f\"Number of samples in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in val_dataset_plant: {len(val_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Image shape (C, H, W): {images.shape}\")\n",
    "print(f\"Label example: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenexploration: Qualität, Bitrate, Verteilung der Labels, Dimension, etc.\n",
    "\n",
    "# Verteilung der Labels im Trainings- und Validierungsdatensatz\n",
    "train_labels = train_dataset.labels_df['Labels']\n",
    "val_labels = val_dataset.labels_df['Labels']\n",
    "\n",
    "print(\"Train label distribution:\")\n",
    "print(train_labels.value_counts())\n",
    "print(\"\\nValidation label distribution:\")\n",
    "print(val_labels.value_counts())\n",
    "\n",
    "# Plot label distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "train_labels.value_counts().plot(kind='bar', title='Train Label Distribution')\n",
    "plt.subplot(1, 2, 2)\n",
    "val_labels.value_counts().plot(kind='bar', title='Validation Label Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show label distribution in a batch from the weighted sampler\n",
    "def plot_batch_label_distribution(loader, name):\n",
    "    batch_imgs, batch_labels = next(iter(loader))\n",
    "    unique, counts = np.unique(batch_labels.cpu().numpy(), return_counts=True)\n",
    "    plt.bar(unique, counts, tick_label=[str(int(u)) for u in unique])\n",
    "    plt.title(f\"{name} batch label distribution\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Weighted sampler batch label distribution (train):\")\n",
    "plot_batch_label_distribution(training_loader, \"Train\")\n",
    "print(\"Weighted sampler batch label distribution (validation):\")\n",
    "plot_batch_label_distribution(validation_loader, \"Validation\")\n",
    "\n",
    "# Beispielbild: Qualität, Dimension, Bitrate\n",
    "sample_img_path = train_dataset.labels_df.iloc[0]['Image']\n",
    "sample_img = Image.open(sample_img_path)\n",
    "print(f\"Sample image path: {sample_img_path}\")\n",
    "print(f\"Image mode: {sample_img.mode}\")\n",
    "print(f\"Image size (W x H): {sample_img.size}\")\n",
    "print(f\"Image format: {sample_img.format}\")\n",
    "\n",
    "# Bitrate (Dateigröße in KB)\n",
    "img_size_kb = os.path.getsize(sample_img_path) / 1024\n",
    "print(f\"Image file size: {img_size_kb:.2f} KB\")\n",
    "\n",
    "# Check for class imbalance\n",
    "imbalance_ratio = train_labels.value_counts().min() / train_labels.value_counts().max()\n",
    "print(f\"Imbalance ratio (min/max): {imbalance_ratio:.3f}\")\n",
    "if imbalance_ratio < 0.5:\n",
    "    print(\"Warning: The dataset is imbalanced!\")\n",
    "\n",
    "# Data augmentation check\n",
    "print(\"\\nData augmentation in use:\")\n",
    "for t in transform.transforms:\n",
    "    print(\"-\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a301",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08509b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4, 4),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=15, padding=7),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4, 4),\n",
    "\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(8 * int(width/(2**7)) * int(height/(2**7)), 4 * int(width/(2**7)) * int(height/(2**7))),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4 * int(width/(2**7)) * int(height/(2**7)), num_classes),\n",
    "            #nn.Sigmoid(),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x #x.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb45998",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics_to_tensorboard(model_name, epoch, test_loss):\n",
    "    writer.add_scalar(f'{model_name}/test_loss', test_loss, epoch)\n",
    "\n",
    "def log_accuracy_to_tensorboard(model_name, epoch, accuracy):\n",
    "    writer.add_scalar(f'{model_name}/accuracy', accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b29643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_config(model, criterion=nn.BCELoss(), learn_rate=0.0001, optim_base=optim.AdamW, epochs=150, patience=10, early_stopping=True,choose_best_loss_model=True):\n",
    "    dic = {}\n",
    "    dic[\"model\"] = model#copy.deepcopy(model)\n",
    "    if criterion: dic[\"criterion\"] = criterion\n",
    "    if learn_rate: dic[\"learn_rate\"] = learn_rate\n",
    "    if optim_base: dic[\"optim_base\"] = optim_base\n",
    "    if epochs: dic[\"epochs\"] = epochs\n",
    "    if early_stopping: dic[\"early_stopping\"] = early_stopping\n",
    "    if choose_best_loss_model: dic[\"choose_best_loss_model\"] = choose_best_loss_model\n",
    "    return dic \n",
    "\n",
    "def simple_train(model, train_loader, val_loader, criterion=nn.BCELoss(), learn_rate=0.0001, optim_base=optim.AdamW, epochs=150, patience=10, early_stopping=True,choose_best_loss_model=True):\n",
    "    # Calculate the total number of parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(f'Total number of parameters: {total_params}')\n",
    "    intro_text = f\"\"\"Training {total_params} Parameters {model._get_name()} with \n",
    "          criterion: {criterion},\n",
    "          optim_base: {optim_base},\n",
    "          learn_rate: {learn_rate}, \n",
    "          epochs: {epochs}, \n",
    "          patience: {patience}, \n",
    "          early_stopping: {early_stopping}, \n",
    "          choose_best_loss_model: {choose_best_loss_model}\"\"\"\n",
    "    print(intro_text)\n",
    "    \n",
    "    print(\"--------\")\n",
    "\n",
    "    hash_int = hash((model._get_name(), criterion, learn_rate, optim_base, epochs, patience, early_stopping, choose_best_loss_model))\n",
    "    writer.add_text(f'{model._get_name()}_{hash_int}/train_loss', intro_text)\n",
    "\n",
    "    optimizer = optim_base(model.parameters(), lr=learn_rate)\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)\n",
    "\n",
    "    # Move the model to GPU if available\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    outer_loop = tqdm(range(epochs), desc=\"Epochs\")\n",
    "    \n",
    "    for epoch in outer_loop:\n",
    "        #print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            if (outputs.shape[1] == 2):\n",
    "                labels = labels.long()\n",
    "            \n",
    "\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            writer.add_scalar(f'{model._get_name()}_{hash_int}/train_loss', loss.detach().item(), epoch*len(train_loader)+idx)\n",
    "            running_loss += loss.detach().item()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #scheduler.step()\n",
    "        #print(f'Training loss: {running_loss / len(train_loader)}')\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                #print(outputs.shape)\n",
    "                if (outputs.shape[1] == 2):\n",
    "                    labels = labels.long()\n",
    "\n",
    "                outputs = outputs.squeeze(-1)\n",
    "\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Convert the outputs to predicted class labels\n",
    "                if (outputs.shape[1] == 2):\n",
    "                    predicted = outputs.argmax(dim=1).float() #torch.max(outputs, 1)\n",
    "                else:\n",
    "                    predicted = (outputs>0.5).float() #torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "\n",
    "        writer.add_scalar(f'{model._get_name()}_{hash_int}/running_loss', running_loss / len(train_loader), epoch)\n",
    "        writer.add_scalar(f'{model._get_name()}_{hash_int}/val_loss', val_loss, epoch)\n",
    "        writer.add_scalar(f'{model._get_name()}_{hash_int}/val_acc', val_accuracy, epoch)\n",
    "\n",
    "        tqdm.set_description_str(outer_loop,f\"Epochs: [acc: ({val_accuracy:.4f}/{best_val_acc:.4f}), loss: ({val_loss:.4f}/{best_val_loss:.4f})]\")\n",
    "        #print(f'Validation loss: {val_loss / len(val_loader)}')\n",
    "        #print(f'Validation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            patience_counter = patience_counter - 1 if patience_counter > 0 else 0\n",
    "            torch.save(model.state_dict(), 'best_acc_model.pth')\n",
    "            #print(f'Best model saved with valid acc of {val_accuracy:.4f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_val_model.pth')\n",
    "            #print(f'Best model saved with valid loss of {val_loss / len(val_loader)}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience and early_stopping:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    if (choose_best_loss_model):\n",
    "        model.load_state_dict(torch.load('best_val_model.pth'))\n",
    "        return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    model.to(device)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, label in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            if (outputs.shape[1] == 2):\n",
    "                predicted = outputs.argmax(dim=1).float()\n",
    "            else:\n",
    "                predicted = (outputs>0.5).float()\n",
    "            labels.extend(label.cpu().numpy())\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Create a DataFrame with IDs and predictions\n",
    "    submission_df = pd.DataFrame({\n",
    "        #'images': test_dataset.labels_df['Images'],\n",
    "        'labels': predictions,\n",
    "        'groundtruth': labels\n",
    "    })\n",
    "\n",
    "    submission_df_ones = submission_df[submission_df.groundtruth == 1]\n",
    "    submission_df_zeros = submission_df[submission_df.groundtruth == 0]\n",
    "    tp = (submission_df_ones.labels == submission_df_ones.groundtruth).sum()\n",
    "    tn = (submission_df_zeros.labels == submission_df_zeros.groundtruth).sum()\n",
    "    fn = (submission_df_ones.labels != submission_df_ones.groundtruth).sum()\n",
    "    fp = (submission_df_zeros.labels != submission_df_zeros.groundtruth).sum()\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fn+fp)\n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    return accuracy, precision, recall, f1, (tp, tn, fn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7588cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_hyper_train(configurations):\n",
    "    model_list = []\n",
    "    for config in configurations: \n",
    "        config[\"train_loader\"] = training_loader\n",
    "        config[\"val_loader\"] = validation_loader\n",
    "        model = simple_train(**config)\n",
    "        model_list.append(model)\n",
    "    results = []\n",
    "    for model in model_list:\n",
    "        accuracy, precision, recall, f1, (tp, tn, fn, fp) = eval(model, test_loader)\n",
    "        result = {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy, \n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall, \n",
    "            \"f1\": f1, \n",
    "            \"hidden\": (tp, tn, fn, fp),\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = mdl.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
    "\n",
    "alexnet = mdl.alexnet(weights=\"IMAGENET1K_V1\")\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unreg_params(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "resnet_last = mdl.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "unreg_params(resnet_last)\n",
    "resnet_last.fc = nn.Linear(resnet_last.fc.in_features, 2)\n",
    "\n",
    "alexnet_last = mdl.alexnet(weights=\"IMAGENET1K_V1\")\n",
    "unreg_params(alexnet_last)\n",
    "alexnet_last.classifier[6] = nn.Linear(alexnet_last.classifier[6].in_features, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    build_config(resnet,criterion=nn.CrossEntropyLoss(), learn_rate=0.01,epochs=75),\n",
    "    build_config(alexnet,criterion=nn.CrossEntropyLoss(), learn_rate=0.01,epochs=75),\n",
    "\n",
    "    build_config(CNN(),criterion=nn.CrossEntropyLoss(), learn_rate=0.01,epochs=75),\n",
    "\n",
    "    build_config(resnet_last,criterion=nn.CrossEntropyLoss(), learn_rate=0.01,epochs=75),\n",
    "    build_config(alexnet_last,criterion=nn.CrossEntropyLoss(), learn_rate=0.01,epochs=75),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95925ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortend(configs):\n",
    "    conf_out = []\n",
    "    for config in configs:\n",
    "        d = {\n",
    "            \"name\": config[\"model\"]._get_name(),\n",
    "            \"accuracy\": float(config[\"accuracy\"]),\n",
    "            \"f1\": float(config[\"f1\"])\n",
    "        }\n",
    "        conf_out.append(d)\n",
    "    return conf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simple_hyper_train(configs)\n",
    "shortend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5427f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference_time(model):\n",
    "    image, label = val_dataset[0]\n",
    "    image = image.unsqueeze(0)\n",
    "    model.cpu()\n",
    "    since = time.time()\n",
    "    model(image)\n",
    "    now = time.time()\n",
    "    now - since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
